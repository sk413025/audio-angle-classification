# Gradient Harmonizing Mechanism (GHM) 訓練結果報告

## 摘要

本報告分析了使用 Gradient Harmonizing Mechanism (GHM) 進行模型訓練的結果。GHM 是一種調整梯度分佈的技術，通過自動重新加權樣本來優化訓練過程，特別是在處理不平衡數據集時。我們將分析 GHM 對訓練過程的影響、梯度分佈的變化以及與傳統損失函數的比較。

## 目錄
1. [GHM 原理簡介](#ghm-原理簡介)
2. [實驗設置](#實驗設置)
3. [訓練結果分析](#訓練結果分析)
4. [梯度分佈分析](#梯度分佈分析)
5. [GHM vs 傳統損失函數](#ghm-vs-傳統損失函數)
6. [進階視覺化分析](#進階視覺化分析)
7. [結論與建議](#結論與建議)

## GHM 原理簡介

Gradient Harmonizing Mechanism (GHM) 是為解決深度學習訓練中的樣本不平衡問題而設計的。在傳統的損失函數中，所有樣本被平等對待，導致容易分類的樣本（通常數量較多）主導訓練過程，而難以分類的樣本（通常數量較少）得不到足夠關注。

GHM 通過以下關鍵步驟解決這個問題：

1. **梯度密度計算**：計算不同樣本梯度大小的分佈
2. **自動重新加權**：根據梯度密度為樣本分配權重，梯度密度高的區域（樣本多）獲得較低權重，密度低的區域（樣本少）獲得較高權重
3. **平衡梯度貢獻**：確保不同難度的樣本對模型訓練的貢獻相對平衡

與 Focal Loss 等需要手動調整超參數的方法相比，GHM 可以自動適應數據分佈，更加靈活且有效。

## 實驗設置

### 模型架構
- 基於 ResNet 的排序模型 (ResNetAudioRanker)
- 輸入：語音頻譜圖
- 輸出：排序得分

### 訓練參數
- **批次大小**：32
- **學習率**：0.03
- **優化器**：Adam
- **訓練輪數**：60 (3000Hz)
- **檢查點間隔**：5 epochs

### GHM 參數
- **bins**：10（梯度密度直方圖的分桶數量）
- **alpha**：0.75（梯度密度調節指數）
- **margin**：10.0（與 MarginRankingLoss 相同的邊界參數）

### 數據集
- **頻率**：3000Hz & 1000Hz
- **材質**：plastic
- **訓練集**：70% 數據
- **驗證集**：30% 數據

## 訓練結果分析

以下我們分析 3000Hz 數據集的完整訓練結果：

![訓練比較圖](training_comparison_20250411_213433.png)

從圖中可以觀察到：

1. **損失函數比較**：
   - GHM 損失（虛線）總體低於原始損失（實線），表明 GHM 通過重新加權樣本，有效降低了總體損失。
   - 訓練集和驗證集的 GHM 損失都更平滑，波動更小，表明訓練更穩定。

2. **準確率變化**：
   - 訓練準確率穩定上升，最終達到高水平。
   - 驗證準確率同樣有提升，但存在一定波動，表明模型在泛化方面仍有改進空間。

3. **收斂速度**：
   - GHM 損失在早期輪數中收斂更快，表明 GHM 可以加速模型學習過程。

4. **過擬合分析**：
   - 訓練損失和驗證損失的差距隨著訓練進行有所增加，但總體可控，未出現明顯過擬合。

## 梯度分佈分析

GHM 的核心機制是根據梯度密度分佈自動重新加權樣本。以下我們分析不同訓練階段的梯度分佈變化：

### 訓練初期（第 1 輪）

![第1輪梯度分佈](epoch1_batch0_20250411_213433.png)

初期階段，梯度分佈相對均勻，GHM 對各個梯度區間的權重調整較為平衡。

### 訓練中期（第 30 輪）

![第30輪梯度分佈](epoch30_batch0_20250411_213433.png)

中期階段，梯度分佈開始出現分化，某些區間的樣本密度增加，GHM 開始加強對低密度區域的權重。

### 訓練後期（第 60 輪）

![第60輪梯度分佈](epoch60_batch0_20250411_213433.png)

後期階段，梯度分佈更加極化，GHM 明顯增加了對低密度區域（困難樣本）的權重，確保這些樣本能夠對模型訓練做出足夠貢獻。

### 梯度分佈演變

![梯度密度演變](gradient_density_evolution.png)

通過梯度密度演變圖，我們可以更清晰地看到訓練過程中梯度分佈的變化趨勢。從初期的相對均勻分佈，到後期的更加集中和極化，反映了模型學習過程中對不同難度樣本的適應性變化。

## 不平衡數據測試結果

為驗證 GHM 在處理不平衡數據方面的效果，我們進行了專門的不平衡數據測試：

![不平衡數據梯度分佈](imbalanced_gradient_distribution.png)

此圖顯示了在不平衡數據集上的梯度分佈情況，可以看到梯度分佈明顯偏斜，大量樣本集中在低梯度區域。

![不平衡數據 GHM 權重](imbalanced_ghm_weights.png)

GHM 根據梯度密度自動調整權重，為低密度區域（通常是困難樣本）分配更高權重，確保它們在訓練中得到足夠關注。

## GHM vs 傳統損失函數

我們使用簡單的線性模型比較了 GHM 與傳統 MarginRankingLoss 的效果：

![訓練比較](training_comparison.png)

比較結果顯示：

1. **損失函數差異**：
   - GHM 損失總體低於傳統損失，表明重新加權機制有效。
   - GHM 損失曲線更平滑，表明訓練更穩定。

2. **準確率比較**：
   - 在初期，傳統損失函數準確率上升更快，可能因為其優先處理容易樣本。
   - 隨著訓練進行，GHM 的準確率逐漸趕上並最終與傳統方法相當。
   - 在某些情況下，GHM 的最終準確率略高，表明其對困難樣本的處理更有效。

3. **收斂特性**：
   - GHM 的收斂過程更加平穩，避免了傳統損失函數可能出現的震盪。
   - GHM 可能需要更多輪數才能達到最佳效果，但最終結果更可靠。

## 進階視覺化分析

### 不同訓練階段的 GHM 權重分佈比較

![GHM 權重分佈比較](ghm_weights_comparison.png)

這張組合圖顯示了訓練的早期、中期和後期階段的 GHM 權重分佈。通過比較可以觀察到：

1. **早期階段**：
   - 權重分佈相對均勻
   - 對所有梯度區間的重視程度相近
   - 模型處於初步學習階段，尚未明確區分困難和簡單樣本

2. **中期階段**：
   - 權重分佈開始呈現明顯變化
   - 某些梯度區間的權重增加，表明 GHM 開始聚焦於這些區間的樣本
   - 反映了模型對數據特徵的進一步理解

3. **後期階段**：
   - 權重分佈更加極化
   - 低頻區域（困難樣本）獲得更高權重
   - 表明模型在處理簡單樣本的同時，更加注重對困難樣本的學習

這種權重分佈的動態變化是 GHM 的核心優勢，能夠根據訓練進展自動調整對不同難度樣本的關注度，避免了傳統損失函數可能出現的樣本失衡問題。

## 結論與建議

基於 GHM 訓練結果分析，我們得出以下結論：

1. **效果評估**：
   - GHM 成功實現了梯度分佈的自動調整，特別適合處理不平衡數據集。
   - GHM 損失函數與傳統損失函數相比，提供更穩定的訓練過程。
   - 最終準確率與傳統方法相當或略優，但訓練過程更加穩定。

2. **優勢**：
   - 自動重新加權機制避免了手動調整樣本權重的繁瑣過程。
   - 對不同難度的樣本都給予適當關注，更全面地學習數據特徵。
   - 訓練過程波動較小，模型收斂更穩定。

3. **局限性**：
   - 計算複雜度略高，訓練時間可能增加。
   - 參數選擇（bins、alpha）仍需一定調整以達最佳效果。

4. **應用建議**：
   - 對於類別不平衡嚴重的數據集，強烈推薦使用 GHM。
   - 建議以 bins=10, alpha=0.75 作為起點，根據具體任務進行微調。
   - 對於需要穩定訓練過程的場景，GHM 是優先選擇。

5. **未來改進方向**：
   - 結合 GHM 與其他優化技術（如學習率調度、數據增強）進一步提升效果。
   - 探索 GHM 參數的自適應調整機制，減少手動調參需求。
   - 針對特定任務（如本項目的音頻數據）優化 GHM 機制以獲得更好效果。

總體而言，GHM 在本項目中展現出良好的效果，特別是在處理不同難度的樣本並維持穩定訓練方面。建議在未來的分類和排序任務中優先考慮使用 GHM 機制。

---

*報告生成日期: 2025年4月11日* 