# 實驗報告: 20250409_050500_multicollinearity_pca_analysis

## 1. 實驗資訊 (Metadata)

*   **實驗編號 (Experiment ID):** 20250409_050500_multicollinearity_pca_analysis
*   **日期時間 (Timestamp):** 2025-04-09 05:05:00
*   **實驗描述 (Description):** 使用 PCA 前處理分析神經網路特徵的共線性
*   **執行者 (Executor):** 系統管理員

## 2. 背景與動機 (Background & Motivation)

深度神經網路的高維度特徵空間常有共線性的問題，也就是特徵之間彼此高度相關。這可能導致下游分析的數值不穩定，並可能影響模型的效能。傳統的共線性分析方法在處理極高維度特徵（例如本例中的 16,384 維）時，計算上變得不可行，因此需要使用降維方法來進行分析。

本實驗要解決的挑戰是如何在高維度特徵空間中有效地分析共線性，同時不失去關於特徵關係的關鍵資訊。先前直接分析完整特徵空間的嘗試導致了計算瓶頸，且提供的見解有限。

## 3. 實驗目的與假說 (Purpose & Hypothesis)

**目的：**

*   實作並評估一種基於 PCA 的前處理方法，用於分析高維度神經網路特徵空間中的共線性。
*   量化透過 PCA 前處理達成的共線性降低程度。
*   比較不同訓練週期（epoch）的共線性指標，以追蹤模型訓練過程中特徵關係的變化。

**假說：**

*   PCA 前處理將有效降低維度，同時保留特徵空間中的主要變異性。
*   經過 PCA 降維後，特徵矩陣的條件數（condition number）將顯著改善。
*   共線性模式可能會在訓練過程中改變，隨著模型學習到更具區別性的特徵，特徵間的相關性可能會降低。

## 4. 方法論 (Methodology)

**資料與模型：**

*   資料集：角度分類資料集，共 6 個類別 (deg000, deg036, deg072, deg108, deg144, deg180)
*   材質：塑膠 (Plastic)
*   頻率：3000Hz
*   模型架構：基於 ResNet 的神經網路，其骨幹網路已凍結，僅訓練分類器層。
*   分析的模型檢查點：Epoch 5, 10, 15, 20, 25, 30

**分析程序：**

1.  **特徵提取：**
    *   從骨幹網路輸出層提取 10 個樣本的特徵。
    *   原始特徵維度：16,384
2.  **PCA 前處理：**
    *   應用 PCA 降低維度，保留 95% 的變異數。
    *   降維後特徵維度：9
3.  **共線性指標：**
    *   計算降維後特徵的相關矩陣。
    *   計算原始及降維後特徵矩陣的條件數。
    *   識別高度相關的特徵對（相關係數 >= 0.9）。
    *   特徵相關矩陣的特徵值分析。
4.  **梯度相關性分析：**
    *   收集 5 個批次的梯度資料。
    *   分析梯度之間的相關性。
5.  **視覺化：**
    *   產生降維後特徵的相關性熱圖。
    *   繪製原始特徵的特徵值分佈圖。
    *   建立跨週期的條件數比較圖。

**實驗環境：**

*   硬體：Mac Studio，使用 MPS 加速
*   軟體：Python 搭配 PyTorch 框架

## 5. 結果與分析 (Results & Analysis)

**PCA 降維：**

*   原始維度：16,384
*   降維後維度：9 (保留 95% 變異數)
*   降維比例：約 1,820:1

**條件數（降維後特徵矩陣）：**

*   Epoch 5: 1.29
*   Epoch 10: 1.26
*   Epoch 15: 1.26
*   Epoch 20: 1.28
*   Epoch 25: 1.24
*   Epoch 30: 1.25

![條件數比較圖](images/condition_number_comparison_reduced.png)
*圖 1：不同訓練週期下降維後特徵矩陣的條件數比較。*
**圖 1 分析：**

*   **動機：** 評估 PCA 降維後特徵矩陣的數值穩定性，並觀察此穩定性在模型訓練過程中的演變。
*   **解讀：** 圖表顯示了不同訓練週期下，經 PCA 降維的特徵矩陣的條件數。在所有分析的週期中，這些數值都維持在低檔（介於 1.24 到 1.29 之間）。
*   **推論：** 接近 1 的條件數表示矩陣狀況良好，主成分之間的共線性極小。跨週期的穩定性顯示 PCA 轉換在整個訓練過程中有效地減緩了共線性問題，確保了使用這些降維特徵進行潛在下游任務時的數值穩健性。

**原始特徵空間分析：**

*   特徵值比率（最大值/最小值）：
    *   Epoch 5: 1.93e+11
    *   Epoch 10: 3.61e+11
    *   Epoch 15: 4.65e+11
    *   Epoch 20: 5.69e+11
    *   Epoch 25: 4.77e+11
    *   Epoch 30: 2.73e+11

**相關性分析：**

*   在降維後的特徵空間中，未發現高度相關的特徵對（|相關係數| >= 0.9）。
*   這表示 PCA 有效地對特徵進行了去相關處理，同時保留了主要的變異性。

**梯度相關性分析：**

*   未識別出高度相關的梯度對。
*   這意味著模型參數的更新方向並非冗餘。

**視覺化分析：**

*   相關性熱圖顯示主成分之間的相關性相對較低。
*   特徵值分佈圖顯示大部分的變異數由前幾個主成分所捕捉。
*   跨週期的條件數比較顯示數值始終維持在低檔，表示良好的數值穩定性。

**各訓練週期視覺化圖表：**

*特徵值分佈圖的一般解讀 (圖 2, 4, 6, 8, 10, 12)：*

*   **動機：** 了解原始高維度特徵空間中的變異數分佈。特徵值的急遽下降意味著少數幾個主成分捕捉了大部分資料的變異數，這證明了降維的合理性。
*   **解讀：** 每張圖都以對數尺度顯示了*原始*特徵相關矩陣排序後的特徵值。可以看到明顯的急遽下降，表示前幾個特徵值遠大於其餘特徵值。最大與最小特徵值之間的極高比率（如內文所述，Epoch 5 約為 1.93e+11）量化了這種差異。
*   **推論：** 這些圖表視覺化地證實了原始 16,384 維特徵空間中存在的嚴重共線性。特徵值的快速衰減強烈支持使用 PCA，因為它顯示維度可以顯著降低（本例中降至 9 維），同時保留絕大多數（95%）的原始特徵變異數。

*相關性熱圖的一般解讀 (圖 3, 5, 7, 9, 11, 13)：*

*   **動機：** 視覺化檢查 PCA *降維後*特徵之間的成對相關性。理想情況下，主成分之間應不相關或相關性極低。
*   **解讀：** 每張熱圖顯示了 PCA 分析產生的 9 個主成分的相關矩陣。對角線元素為 1（特徵與自身的相關性）。非對角線元素代表不同主成分之間的成對相關性。顏色越接近白色/淺黃色，表示相關性接近 0；顏色越深則表示越強的正相關或負相關。
*   **推論：** 熱圖一致地顯示非對角線區域主要呈現淺色，表示主成分之間的相關性非常低。這視覺化地證實了 PCA 轉換已成功地對原始特徵進行去相關處理，產生了一組大致獨立的主成分。這也印證了低條件數的發現。

*Epoch 5：*
![Epoch 5 特徵值分佈圖](images/eigenvalue_distribution_original_epoch_5.png)
*圖 2：原始特徵的特徵值分佈圖 (Epoch 5)。*

![Epoch 5 相關性熱圖](images/correlation_heatmap_reduced_epoch_5.png)
*圖 3：PCA 降維後特徵的相關性熱圖 (Epoch 5)。*

*Epoch 10：*
![Epoch 10 特徵值分佈圖](images/eigenvalue_distribution_original_epoch_10.png)
*圖 4：原始特徵的特徵值分佈圖 (Epoch 10)。*

![Epoch 10 相關性熱圖](images/correlation_heatmap_reduced_epoch_10.png)
*圖 5：PCA 降維後特徵的相關性熱圖 (Epoch 10)。*

*Epoch 15：*
![Epoch 15 特徵值分佈圖](images/eigenvalue_distribution_original_epoch_15.png)
*圖 6：原始特徵的特徵值分佈圖 (Epoch 15)。*

![Epoch 15 相關性熱圖](images/correlation_heatmap_reduced_epoch_15.png)
*圖 7：PCA 降維後特徵的相關性熱圖 (Epoch 15)。*

*Epoch 20：*
![Epoch 20 特徵值分佈圖](images/eigenvalue_distribution_original_epoch_20.png)
*圖 8：原始特徵的特徵值分佈圖 (Epoch 20)。*

![Epoch 20 相關性熱圖](images/correlation_heatmap_reduced_epoch_20.png)
*圖 9：PCA 降維後特徵的相關性熱圖 (Epoch 20)。*

*Epoch 25：*
![Epoch 25 特徵值分佈圖](images/eigenvalue_distribution_original_epoch_25.png)
*圖 10：原始特徵的特徵值分佈圖 (Epoch 25)。*

![Epoch 25 相關性熱圖](images/correlation_heatmap_reduced_epoch_25.png)
*圖 11：PCA 降維後特徵的相關性熱圖 (Epoch 25)。*

*Epoch 30：*
![Epoch 30 特徵值分佈圖](images/eigenvalue_distribution_original_epoch_30.png)
*圖 12：原始特徵的特徵值分佈圖 (Epoch 30)。*

![Epoch 30 相關性熱圖](images/correlation_heatmap_reduced_epoch_30.png)
*圖 13：PCA 降維後特徵的相關性熱圖 (Epoch 30)。*

實驗結果強烈支持 PCA 前處理對於共線性分析的有效性。維度從 16,384 大幅降至 9，同時保留了 95% 的變異數，這顯示了原始特徵空間中固有的冗餘性。原始空間中極高的特徵值比率（約 10^11 等級）證實了嚴重的共線性問題，而 PCA 轉換有效地解決了這個問題，使得條件數接近 1。

跨訓練週期的條件數一致性表明，即使模型分類效能有所提升，特徵空間的基本結構在訓練過程中仍保持穩定。

## 6. 結論與未來工作 (Conclusion & Future Work)

**結論：**

1.  對於高維度神經網路特徵空間的共線性分析，PCA 前處理非常有效，能將維度降低三個數量級，同時保留必要的資訊。
2.  降維後特徵矩陣的條件數（1.24-1.29）顯示了 PCA 轉換後優異的數值穩定性，與原始空間中的嚴重共線性形成鮮明對比。
3.  跨訓練週期的條件數一致性表明，特徵空間的基本結構在訓練期間保持穩定，模型可能是透過更佳地利用現有特徵來提升效能，而非發展全新的特徵表示。

**限制：**

1.  分析僅基於相對較小的樣本（10 個實例），可能無法完全代表特徵空間的多樣性。
2.  固定的變異數閾值（95%）可能需要針對不同的模型或資料集進行調整。
3.  用於判斷高度相關的二元閾值（0.9）有些武斷，可能會忽略低於此閾值的重要相關模式。

**未來工作：**

1.  探索基於特徵值分佈的自適應 PCA 變異數閾值。
2.  實作跨不同材質和頻率的比較分析，以識別特定領域的共線性模式。
3.  研究共線性指標與模型效能指標（準確率、損失）之間的關係，以建立潛在的因果關係。
4.  將分析擴展到包含其他降維技術（如 t-SNE, UMAP）以與 PCA 進行比較。
5.  開發互動式視覺化工具，用於探索不同粒度的特徵相關性。 