# 共線性分析實驗概述

## 背景與動機

深度神經網路中的高維特徵空間常存在共線性問題，即特徵之間高度相關。這種共線性可能導致：

- 數值計算不穩定
- 模型解釋性降低
- 下游分析任務的效率與準確性下降

傳統的共線性分析方法在處理非常高維的特徵空間（如本例中的16,384維）時，計算成本過高且效率低下。過去嘗試直接分析完整特徵空間的方法遇到了計算瓶頸，並且難以提供有意義的見解。

## 實驗目的

本實驗旨在：

1. 實現並評估基於PCA的預處理方法，以高效分析高維神經網路特徵空間中的共線性
2. 量化PCA預處理對共線性降低的效果
3. 比較不同訓練階段（Epoch）的共線性指標，追蹤特徵關係在模型訓練過程中的變化

## 實驗假說

1. PCA預處理將有效降低特徵維度，同時保留特徵空間中的本質變異性
2. 特徵矩陣的條件數（condition number）將在PCA降維後顯著改善
3. 共線性模式可能會在訓練過程中發生變化，隨著模型學習更具辨別力的特徵，特徵間相關性可能會降低

## 操作步驟

1. **準備環境與資料**
   - 使用角度分類資料集（6個類別：deg000, deg036, deg072, deg108, deg144, deg180）
   - 材質：塑料
   - 頻率：3000Hz
   - 模型：基於ResNet的神經網路（凍結主幹網路，僅訓練分類器層）

2. **執行分析**
   - 運行命令：`python visualizations/visualize_multicollinearity.py`
   - 在提示時選擇頻率（選擇3：3000Hz）
   - 設定PCA方差閾值（預設0.95）
   - 選擇分析的檢查點（選擇"all"分析所有檢查點）

3. **結果解釋**
   - 檢視生成的相關性熱圖（correlation heatmaps）
   - 分析特徵值分佈圖（eigenvalue distributions）
   - 比較不同訓練階段的條件數變化

## 預期結果

1. **維度降低**：從16,384維降至約10維左右，同時保留95%的方差
2. **共線性指標改善**：
   - PCA降維後的條件數接近1，表示數值穩定性良好
   - 原始特徵空間的特徵值比率極高（10^11數量級），確認嚴重共線性
   - PCA轉換後的主成分之間相關性低
3. **訓練進程的影響**：
   - 條件數在不同訓練階段保持穩定，表明特徵空間的基本結構在訓練過程中相對穩定
   - 模型性能提升主要通過更有效地利用現有特徵，而非發展全新的特徵表示

## 結果應用價值

1. 為高維神經網路特徵的共線性分析提供可行的計算方法
2. 通過識別冗餘特徵，優化模型結構和特徵提取過程
3. 加深對神經網路內部特徵關係和表示學習過程的理解
4. 為後續研究提供基準和比較框架，特別是針對不同材質和頻率的條件 